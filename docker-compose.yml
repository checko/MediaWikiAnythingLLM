services:
  anythingllm:
    image: mintplexlabs/anythingllm:latest
    container_name: anythingllm
    ports:
      - "${SERVER_PORT:-3001}:3001"
    environment:
      - STORAGE_DIR=/app/server/storage
      # LLM Configuration (from .env)
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - OLLAMA_BASE_PATH=${OLLAMA_BASE_PATH:-http://host.docker.internal:11434}
      - OLLAMA_MODEL_PREF=${OLLAMA_MODEL_PREF:-llama3}
      # Embedding Configuration (from .env)
      - EMBEDDING_ENGINE=${EMBEDDING_ENGINE:-ollama}
      - EMBEDDING_BASE_PATH=${EMBEDDING_BASE_PATH:-http://host.docker.internal:11434}
      - EMBEDDING_MODEL_PREF=${EMBEDDING_MODEL_PREF:-nomic-embed-text}
      # Vector Database Configuration
      - VECTOR_DB=${VECTOR_DB:-lancedb}
      # Server Configuration
      - SERVER_PORT=3001
      - JWT_SECRET=${JWT_SECRET:-change-this-secret-in-production}
      # Optional: Disable telemetry
      - DISABLE_TELEMETRY=${DISABLE_TELEMETRY:-true}
    volumes:
      - ./storage:/app/server/storage
    restart: unless-stopped
    cap_add:
      - SYS_ADMIN
    extra_hosts:
      - "host.docker.internal:host-gateway"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/api/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

volumes:
  anythingllm_storage:
